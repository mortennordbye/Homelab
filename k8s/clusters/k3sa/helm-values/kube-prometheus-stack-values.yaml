# Disable CRD management
crds:
  enabled: false
# Default alerting rules configuration
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8sContainerCpuUsageSecondsTotal: true
    k8sContainerMemoryCache: true
    k8sContainerMemoryRss: true
    k8sContainerMemorySwap: true
    k8sContainerResource: true
    k8sContainerMemoryWorkingSetBytes: true
    k8sPodOwner: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubeControllerManager: true
    kubelet: true
    kubeProxy: false
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeSchedulerAlerting: true
    kubeSchedulerRecording: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
    windows: true
# Alertmanager configuration
alertmanager:
  enabled: true
  config:
    global:
      resolve_timeout: 5m
    inhibit_rules:
      - source_matchers:
          - 'severity = critical'
        target_matchers:
          - 'severity =~ warning|info'
        equal:
          - 'namespace'
          - 'alertname'
      - source_matchers:
          - 'severity = warning'
        target_matchers:
          - 'severity = info'
        equal:
          - 'namespace'
          - 'alertname'
      - source_matchers:
          - 'alertname = InfoInhibitor'
        target_matchers:
          - 'severity = info'
        equal:
          - 'namespace'
      - target_matchers:
          - 'alertname = InfoInhibitor'
    route:
      group_by: ['namespace']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'discord'
      routes:
      - receiver: 'discord'
        matchers:
          - alertname = "Watchdog"
    receivers:
    - name: 'discord'
      discord_configs:
        webhook_url: https://discordapp.com/api/webhooks/1368506706413224067/AelHgudWv8aY2j0bLnAnU3BzJOmlMq-6MTq-tpAnDf4t6FjrMSVB3Gyo2B1CVtiTHOaH
    - name: 'null'
    templates:
    - '/etc/alertmanager/config/*.tmpl'
  alertmanagerSpec:
    logLevel: debug
    replicas: 1
    retention: 48h
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: "nfs-client"
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 5Gi
    secrets:
      - alertmanager-discord-webhook-secret
# Grafana configuration
grafana:
  enabled: true
  forceDeployDatasources: false
  forceDeployDashboards: false
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: Europe/Oslo
  defaultDashboardsEditable: true
  defaultDashboardsInterval: 24h
  serviceMonitor:
    enabled: true
# Follow up this one
  admin:
    existingSecret: grafana-admin-credentials
    userKey: admin-user
    passwordKey: admin-password
  persistence:
    enabled: true
    storageClassName: "nfs-client"
    accessModes: ["ReadWriteOnce"]
    size: 5Gi
    finalizers:
      - kubernetes.io/pvc-protection
# Core Kubernetes component configurations
kubeApiServer:
  enabled: true
kubelet:
  enabled: true
  namespace: kube-system
  serviceMonitor:
    enabled: true
    kubelet: true
kubeControllerManager:
  enabled: true
  endpoints:
    - 10.0.0.51
    - 10.0.0.52
    - 10.0.0.53
coreDns:
  enabled: true
kubeDns:
  enabled: false
kubeEtcd:
  enabled: true
  endpoints:
    - 10.0.0.51
    - 10.0.0.52
    - 10.0.0.53

kubeScheduler:
  enabled: true
  endpoints:
    - 10.0.0.51
    - 10.0.0.52
    - 10.0.0.53
kubeProxy:
  enabled: false
kubeStateMetrics:
  enabled: true
# Prometheus node exporter configuration
nodeExporter:
  enabled: false
# Prometheus configuration
prometheus:
  enabled: true
  prometheusSpec:
    replicas: 1
    retention: 6h
    enableAdminAPI: true
    walCompression: true
    scrapeInterval: 30s
    evaluationInterval: 30s
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: "nfs-client"
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
    ruleSelectorNilUsesHelmValues: false
    ruleSelector: {}
    ruleNamespaceSelector: {}
    additionalScrapeConfigs:
      - job_name: 'external-node-exporter'
        static_configs:
          - targets: ['10.0.0.21:9100']
            labels:
              instance: 'adguard'
          - targets: ['10.0.0.22:9100']
            labels:
              instance: 'bind'
          - targets: ['10.0.0.25:9100']
            labels:
              instance: 'linbast'
          - targets: ['10.0.0.27:9100']
            labels:
              instance: 'docker-utility'
          - targets: ['10.0.0.28:9100']
            labels:
              instance: 'docker-piracy'
          - targets: ['10.0.0.29:9100']
            labels:
              instance: 'qbittorrent'
          - targets: ['10.0.0.31:9100']
            labels:
              instance: 'plex'
          - targets: ['10.0.0.32:9100']
            labels:
              instance: 'docker-nextcloud'
          - targets: ['10.0.0.36:9100']
            labels:
              instance: 'gitlab'
          - targets: ['10.0.0.39:9100']
            labels:
              instance: 'nfs'
          - targets: ['10.0.0.51:9100']
            labels:
              instance: 'k3sam1'
          - targets: ['10.0.0.52:9100']
            labels:
              instance: 'k3sam2'
          - targets: ['10.0.0.53:9100']
            labels:
              instance: 'k3sam3'
          - targets: ['10.0.0.54:9100']
            labels:
              instance: 'k3saca1'
          - targets: ['10.0.0.55:9100']
            labels:
              instance: 'k3saca2'
          - targets: ['10.0.0.56:9100']
            labels:
              instance: 'k3saca3'
          - targets: ['10.0.0.80:9100']
            labels:
              instance: 'test-vm'
# ThanosRuler configuration
thanosRuler:
  enabled: false
