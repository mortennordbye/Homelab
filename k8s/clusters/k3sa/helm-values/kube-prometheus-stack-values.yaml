# CRD management
crds:
  enabled: false
# Default alerting rules configuration
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8sContainerCpuUsageSecondsTotal: true
    k8sContainerMemoryCache: true
    k8sContainerMemoryRss: true
    k8sContainerMemorySwap: true
    k8sContainerResource: true
    k8sContainerMemoryWorkingSetBytes: true
    k8sPodOwner: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubeControllerManager: true
    kubelet: true
    kubeProxy: false
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeSchedulerAlerting: true
    kubeSchedulerRecording: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
    windows: true
# Alertmanager configuration
alertmanager:
  enabled: true
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname', 'job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'discord'
      routes:
      - receiver: 'discord'
        matchers:
          - alertname = "Watchdog"
    receivers:
    - name: discord
      webhook_configs:
        - url_file: /etc/alertmanager/secrets/alertmanager-discord-webhook-secret/webhook_url
          send_resolved: true
          http_config:
            headers:
              Content-Type: "application/json"
          body: |
            {{ template "discord.default.message" . }}
    - name: 'null'
    templates:
    - '/etc/alertmanager/config/*.tmpl'
  alertmanagerSpec:
    logLevel: debug
    replicas: 1
    retention: 168h
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: "syno-nfs"
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 5Gi
    secrets:
      - alertmanager-discord-webhook-secret
# Grafana configuration
grafana:
  enabled: true
  forceDeployDatasources: false
  forceDeployDashboards: false
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: Europe/Oslo
  defaultDashboardsEditable: true
  defaultDashboardsInterval: 24h
  serviceMonitor:
    enabled: true
# Follow up this one
  admin:
    existingSecret: grafana-admin-credentials
    userKey: admin-user
    passwordKey: admin-password
  persistence:
    enabled: true
    storageClassName: "syno-nfs"
    accessModes: ["ReadWriteOnce"]
    size: 5Gi
    finalizers:
      - kubernetes.io/pvc-protection
# Core Kubernetes component configurations
kubeApiServer:
  enabled: true
kubelet:
  enabled: true
  namespace: kube-system
  serviceMonitor:
    enabled: true
    kubelet: true
kubeControllerManager:
  enabled: true
  endpoints:
    - 10.0.0.51
    - 10.0.0.52
    - 10.0.0.53
coreDns:
  enabled: true
kubeDns:
  enabled: false
kubeEtcd:
  enabled: true
  endpoints:
    - 10.0.0.51
    - 10.0.0.52
    - 10.0.0.53

kubeScheduler:
  enabled: true
  endpoints:
    - 10.0.0.51
    - 10.0.0.52
    - 10.0.0.53
kubeProxy:
  enabled: false
kubeStateMetrics:
  enabled: true
# Prometheus node exporter configuration
nodeExporter:
  enabled: false
# Prometheus configuration
prometheus:
  enabled: true
  prometheusSpec:
    replicas: 1
    retentionSize: "20GiB"
    enableAdminAPI: true
    walCompression: true
    scrapeInterval: 30s
    evaluationInterval: 30s
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: "syno-nfs"
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 30Gi
    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}
    serviceMonitorNamespaceSelector: {}
    ruleSelectorNilUsesHelmValues: false
    ruleSelector: {}
    ruleNamespaceSelector: {}
    scrapeConfigSelectorNilUsesHelmValues: false
    scrapeConfigSelector:
      matchLabels:
        release: prometheus
    additionalScrapeConfigs:
      - job_name: 'external-node-exporter'
        static_configs:
          - targets: ['10.0.0.21:9100']
            labels:
              instance: 'adguard'
          - targets: ['10.0.0.22:9100']
            labels:
              instance: 'bind'
          - targets: ['10.0.0.25:9100']
            labels:
              instance: 'linbast'
          - targets: ['10.0.0.26:9100']
            labels:
              instance: 'docker-alfa'              
          - targets: ['10.0.0.27:9100']
            labels:
              instance: 'docker-utility'
          - targets: ['10.0.0.28:9100']
            labels:
              instance: 'docker-piracy'
          - targets: ['10.0.0.29:9100']
            labels:
              instance: 'qbittorrent'
          - targets: ['10.0.0.31:9100']
            labels:
              instance: 'plex'
          - targets: ['10.0.0.32:9100']
            labels:
              instance: 'docker-nextcloud'
          - targets: ['10.0.0.36:9100']
            labels:
              instance: 'gitlab'
          - targets: ['10.0.0.39:9100']
            labels:
              instance: 'nfs'
          - targets: ['10.0.0.51:9100']
            labels:
              instance: 'k3sam1'
          - targets: ['10.0.0.52:9100']
            labels:
              instance: 'k3sam2'
          - targets: ['10.0.0.53:9100']
            labels:
              instance: 'k3sam3'
          - targets: ['10.0.0.54:9100']
            labels:
              instance: 'k3saca1'
          - targets: ['10.0.0.55:9100']
            labels:
              instance: 'k3saca2'
          - targets: ['10.0.0.56:9100']
            labels:
              instance: 'k3saca3'
          - targets: ['10.0.0.80:9100']
            labels:
              instance: 'test-vm'
# ThanosRuler configuration
thanosRuler:
  enabled: false
